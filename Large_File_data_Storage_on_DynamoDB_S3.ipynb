{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import boto3\n",
    "    from botocore.exceptions import ClientError\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    import _pickle as pickle\n",
    "    import bz2\n",
    "    import sys\n",
    "    from io import BytesIO\n",
    "    import os\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error: {}\".format(e))\n",
    "\n",
    "bucketname = \"dataset-store-und\"\n",
    "\n",
    "'''\n",
    "Attributes of Item to be saved in DynamoDB:\n",
    "uuid -> ID of user\n",
    "dataset_id -> ID or name of dataset\n",
    "pid -> ID of the last completed process\n",
    "data -> compressed data in case of file_size < 400KB | s3 object key (dataset_name) otherwise\n",
    "data_stored_on -> True if data is stored on s3 | False if stored in DynamoDB\n",
    "'''\n",
    "\n",
    "def create_db_table(dynamodb=None):\n",
    "    if not dynamodb:\n",
    "        dynamodb = boto3.resource('dynamodb')\n",
    "\n",
    "    table = dynamodb.create_table(\n",
    "        TableName = 'Datasets',\n",
    "        KeySchema = [\n",
    "            {\n",
    "                'AttributeName': 'uuid',\n",
    "                'KeyType': 'HASH' #Partition Key\n",
    "            },\n",
    "            {\n",
    "                'AttributeName': 'dataset_id',\n",
    "                'KeyType': 'RANGE' #Sort Key\n",
    "            }\n",
    "        ],\n",
    "        AttributeDefinitions = [\n",
    "            {\n",
    "                'AttributeName': 'uuid',\n",
    "                'AttributeType': 'N'\n",
    "            },\n",
    "            {\n",
    "                'AttributeName': 'dataset_id',\n",
    "                'AttributeType': 'S'\n",
    "            }\n",
    "        ],\n",
    "        ProvisionedThroughput = {\n",
    "            'ReadCapacityUnits': 10,\n",
    "            'WriteCapacityUnits': 10\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_db_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(uuid, itemname, dynamodb=None):\n",
    "    if not dynamodb:\n",
    "        dynamodb = boto3.resource('dynamodb')\n",
    "\n",
    "    db_table = dynamodb.Table('Datasets')\n",
    "\n",
    "    with open(itemname,\"r\") as file:\n",
    "        df = pd.read_csv(file)\n",
    "    data = pickle.dumps(df)\n",
    "\n",
    "    #Compress using bz2\n",
    "    compress_data = bz2.compress(data)\n",
    "\n",
    "    #check file size\n",
    "    data_size = sys.getsizeof(compress_data)\n",
    "\n",
    "    if(data_size < 400000):\n",
    "        # save in dynamo\n",
    "        try:\n",
    "            db_table.put_item(\n",
    "                Item = {\n",
    "                    'uuid': uuid,\n",
    "                    'dataset_id': itemname,\n",
    "                    'pid': 1,\n",
    "                    'data': compress_data,\n",
    "                    'data_stored_on': False\n",
    "                }\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\"Error: {}\".format(e))\n",
    "\n",
    "    else:\n",
    "        #save on s3\n",
    "        s3 = boto3.resource('s3')\n",
    "        filename = itemname.split('.')\n",
    "        filename = filename[0]+\".txt\"\n",
    "\n",
    "        bz2_body = BytesIO()\n",
    "        bz2_f = bz2.BZ2File(bz2_body, 'wb', compresslevel=9)\n",
    "        bz2_f.write(compress_data)\n",
    "        bz2_f.close()\n",
    "\n",
    "        try:\n",
    "            obj = s3.Object(bucketname,itemname)\n",
    "            obj.put(ContentType = 'text/plain', ContentEncoding = 'bz2', Body = bz2_body.getvalue())\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Error: \".format(e))\n",
    "\n",
    "        db_table.put_item(\n",
    "            Item = {\n",
    "                'uuid': uuid,\n",
    "                'dataset_id': itemname,\n",
    "                'pid': 1,\n",
    "                'data': itemname,\n",
    "                'data_stored_on': True\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".git\n",
      ".gitignore\n",
      ".ipynb_checkpoints\n",
      "Creating Table.ipynb\n",
      "env\n",
      "flights.csv\n",
      "Get Items from DB.ipynb\n",
      "Large_File_data_Storage_on_DynamoDB_S3.ipynb\n",
      "Use the existing Table.ipynb\n"
     ]
    }
   ],
   "source": [
    "for x in os.listdir():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_data(uuid=1,itemname=\"flights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(uuid, dataset_name=None, dynamodb=None):\n",
    "    if not dynamodb:\n",
    "        dynamodb = boto3.resource('dynamodb')\n",
    "\n",
    "    table = dynamodb.Table('Datasets')\n",
    "\n",
    "    try:\n",
    "        response = table.get_item(Key = { 'uuid': uuid, 'dataset_id': dataset_name })\n",
    "    except ClientError as e:\n",
    "        print(e.response['Error']['Message'])\n",
    "    else:\n",
    "        data_stored_on = response['Item']['data_stored_on']\n",
    "\n",
    "        if data_stored_on:\n",
    "            # fetch from s3\n",
    "            try:\n",
    "                s3 = boto3.resource('s3')\n",
    "                obj = s3.Object(bucketname, dataset_name)\n",
    "                compressed_file = obj.get()['Body']\n",
    "            \n",
    "                with bz2.open(compressed_file,\"rb\") as f:\n",
    "                        compressed_data = f.read()\n",
    "\n",
    "                decompress_data = bz2.decompress(compressed_data)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Error while fetching from s3: {}\".format(e))\n",
    "\n",
    "        else:\n",
    "            #fetch from dynamo\n",
    "            compressed_data = response['Item']['data']\n",
    "            decompress_data = bz2.decompress(compressed_data.value)\n",
    "\n",
    "        unpickle_data = pickle.loads(decompress_data)\n",
    "        print(unpickle_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year      month  passengers\n",
      "0    1949    January         112\n",
      "1    1949   February         118\n",
      "2    1949      March         132\n",
      "3    1949      April         129\n",
      "4    1949        May         121\n",
      "..    ...        ...         ...\n",
      "139  1960     August         606\n",
      "140  1960  September         508\n",
      "141  1960    October         461\n",
      "142  1960   November         390\n",
      "143  1960   December         432\n",
      "\n",
      "[144 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data_file = get_data(uuid=1,dataset_name=\"flights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
